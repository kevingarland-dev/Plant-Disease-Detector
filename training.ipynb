{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596e2bc-7a6d-47d5-92fa-f05894c1e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as  plt\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a62f5f-213f-43b7-8d5f-68fb038fbf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "CHANNEL = 3\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5cd7d8-10ff-419d-aeed-4ded83fccdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \n",
    "        \"PlantVillage\",\n",
    "        shuffle = True,\n",
    "        image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size = BATCH_SIZE\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5edf0-c33a-4621-a1e9-400af27540c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca64e744-7a57-4be0-b5ef-8497fe933c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8 \n",
    "test_size = 0.1\n",
    "validation_size = 0.1\n",
    "\n",
    "len(dataset) * test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b516a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.take(604)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ca803",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset.skip(604)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf2c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = test_dataset.take(76)\n",
    "len(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = test_dataset.skip(76)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adddba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.Rescaling(1.0/255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec676e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2)\n",
    "    \n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b679192",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNEL)\n",
    "classes_number = 17\n",
    "model = models.Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = input_shape ),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, kernel_size= (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, kernel_size= (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation= 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation= 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(classes_number, activation = 'softmax')\n",
    "    \n",
    "    \n",
    "])\n",
    "\n",
    "model.build(input_shape = input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecf17c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = EPOCHS,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    verbose = 1,\n",
    "    validation_data = val_dataset\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec806c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80f4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bae4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9dd651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for images_batch, labels_batch in test_dataset.take(1):\n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "    \n",
    "    print(\"First image to predict\")\n",
    "    plt.imshow(first_image)\n",
    "    print(\"actual Disease:\", class_names[first_label])\n",
    "    batch_prediction = model.predict(images_batch)\n",
    "    print(\"Predicted Disease:\", class_names[np.argmax(batch_prediction[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc0048",
   "metadata": {},
   "source": [
    "# Transfer Learning Implementation\n",
    "\n",
    "Now let's implement transfer learning using pre-trained models to improve validation accuracy. We'll try several popular architectures and compare their performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "209254ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional modules for transfer learning\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0, MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c781009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing layers updated for transfer learning\n"
     ]
    }
   ],
   "source": [
    "# Updated preprocessing for transfer learning\n",
    "# Most pre-trained models expect inputs in range [0,1] or [-1,1]\n",
    "resize_and_rescale_tl = tf.keras.Sequential([\n",
    "    layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    layers.Rescaling(1.0/255)  # Normalize to [0,1]\n",
    "])\n",
    "\n",
    "# Enhanced data augmentation for better generalization\n",
    "data_augmentation_enhanced = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "print(\"Preprocessing layers updated for transfer learning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0c9b735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfer learning model creation function defined\n"
     ]
    }
   ],
   "source": [
    "def create_transfer_learning_model(base_model_name='resnet50', input_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNEL), \n",
    "                                  num_classes=classes_number, trainable_base=False):\n",
    "    \"\"\"\n",
    "    Create a transfer learning model using pre-trained base models\n",
    "    \n",
    "    Args:\n",
    "        base_model_name: 'resnet50', 'efficientnet', or 'mobilenet'\n",
    "        input_shape: Input shape for the model\n",
    "        num_classes: Number of output classes\n",
    "        trainable_base: Whether to make base model layers trainable\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load pre-trained base model\n",
    "    if base_model_name.lower() == 'resnet50':\n",
    "        base_model = ResNet50(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    elif base_model_name.lower() == 'efficientnet':\n",
    "        base_model = EfficientNetB0(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    elif base_model_name.lower() == 'mobilenet':\n",
    "        base_model = MobileNetV2(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported base model. Choose from: 'resnet50', 'efficientnet', 'mobilenet'\")\n",
    "    \n",
    "    # Freeze base model layers initially\n",
    "    base_model.trainable = trainable_base\n",
    "    \n",
    "    # Create the complete model\n",
    "    model = models.Sequential([\n",
    "        resize_and_rescale_tl,\n",
    "        data_augmentation_enhanced,\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "print(\"Transfer learning model creation function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ee2fad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ResNet50 transfer learning model...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
      "ResNet50 model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create ResNet50 transfer learning model\n",
    "print(\"Creating ResNet50 transfer learning model...\")\n",
    "resnet_model, resnet_base = create_transfer_learning_model('resnet50')\n",
    "\n",
    "# Compile the model\n",
    "resnet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"ResNet50 model summary:\")\n",
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70b840c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Callbacks configured for optimal training\n"
     ]
    }
   ],
   "source": [
    "# Setup callbacks for better training\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_resnet_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured for optimal training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2493f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet50 model with transfer learning\n",
    "print(\"Training ResNet50 model with frozen base layers...\")\n",
    "EPOCHS_TL = 15  # More epochs for transfer learning\n",
    "\n",
    "history_resnet = resnet_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS_TL,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"ResNet50 training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbda43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning: Unfreeze some layers for better performance\n",
    "print(\"Starting fine-tuning phase...\")\n",
    "\n",
    "# Unfreeze the top layers of the base model\n",
    "resnet_base.trainable = True\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = len(resnet_base.layers) - 20\n",
    "\n",
    "# Freeze all the layers before fine_tune_at\n",
    "for layer in resnet_base.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "resnet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001/10),  # Lower learning rate\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning from layer {fine_tune_at} onwards\")\n",
    "print(f\"Total layers: {len(resnet_base.layers)}\")\n",
    "print(f\"Trainable layers: {sum([layer.trainable for layer in resnet_base.layers])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1c0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning training\n",
    "fine_tune_epochs = 10\n",
    "total_epochs = len(history_resnet.history['accuracy']) + fine_tune_epochs\n",
    "\n",
    "# Update callbacks for fine-tuning\n",
    "callbacks_finetune = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=3,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-8,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_resnet_finetuned.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_fine = resnet_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=len(history_resnet.history['accuracy']),\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=callbacks_finetune,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the transfer learning model\n",
    "print(\"Evaluating ResNet50 transfer learning model...\")\n",
    "resnet_scores = resnet_model.evaluate(test_dataset, verbose=1)\n",
    "print(f\"ResNet50 Test Accuracy: {resnet_scores[1]:.4f}\")\n",
    "print(f\"ResNet50 Test Loss: {resnet_scores[0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fc0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Original vs Transfer Learning Models\n",
    "def plot_training_comparison(original_history, transfer_history, fine_history=None):\n",
    "    \"\"\"Plot comparison between original and transfer learning training\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Combine transfer learning and fine-tuning histories\n",
    "    if fine_history:\n",
    "        tl_acc = transfer_history.history['accuracy'] + fine_history.history['accuracy']\n",
    "        tl_val_acc = transfer_history.history['val_accuracy'] + fine_history.history['val_accuracy']\n",
    "        tl_loss = transfer_history.history['loss'] + fine_history.history['loss']\n",
    "        tl_val_loss = transfer_history.history['val_loss'] + fine_history.history['val_loss']\n",
    "    else:\n",
    "        tl_acc = transfer_history.history['accuracy']\n",
    "        tl_val_acc = transfer_history.history['val_accuracy']\n",
    "        tl_loss = transfer_history.history['loss']\n",
    "        tl_val_loss = transfer_history.history['val_loss']\n",
    "    \n",
    "    # Training Accuracy Comparison\n",
    "    axes[0, 0].plot(original_history.history['accuracy'], 'b-', label='Original CNN', linewidth=2)\n",
    "    axes[0, 0].plot(tl_acc, 'r-', label='ResNet50 Transfer Learning', linewidth=2)\n",
    "    axes[0, 0].set_title('Training Accuracy Comparison')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation Accuracy Comparison\n",
    "    axes[0, 1].plot(original_history.history['val_accuracy'], 'b-', label='Original CNN', linewidth=2)\n",
    "    axes[0, 1].plot(tl_val_acc, 'r-', label='ResNet50 Transfer Learning', linewidth=2)\n",
    "    axes[0, 1].set_title('Validation Accuracy Comparison')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training Loss Comparison\n",
    "    axes[1, 0].plot(original_history.history['loss'], 'b-', label='Original CNN', linewidth=2)\n",
    "    axes[1, 0].plot(tl_loss, 'r-', label='ResNet50 Transfer Learning', linewidth=2)\n",
    "    axes[1, 0].set_title('Training Loss Comparison')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Loss')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation Loss Comparison\n",
    "    axes[1, 1].plot(original_history.history['val_loss'], 'b-', label='Original CNN', linewidth=2)\n",
    "    axes[1, 1].plot(tl_val_loss, 'r-', label='ResNet50 Transfer Learning', linewidth=2)\n",
    "    axes[1, 1].set_title('Validation Loss Comparison')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Loss')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics comparison\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"FINAL PERFORMANCE COMPARISON\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Original CNN - Final Val Accuracy: {original_history.history['val_accuracy'][-1]:.4f}\")\n",
    "    print(f\"Transfer Learning - Final Val Accuracy: {tl_val_acc[-1]:.4f}\")\n",
    "    print(f\"Improvement: {(tl_val_acc[-1] - original_history.history['val_accuracy'][-1]):.4f}\")\n",
    "    print(f\"Relative Improvement: {((tl_val_acc[-1] - original_history.history['val_accuracy'][-1]) / original_history.history['val_accuracy'][-1] * 100):.2f}%\")\n",
    "\n",
    "# Plot the comparison (you'll run this after training both models)\n",
    "# plot_training_comparison(history, history_resnet, history_fine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Transfer Learning Models\n",
    "print(\"Creating alternative transfer learning models for comparison...\")\n",
    "\n",
    "# EfficientNet Model\n",
    "print(\"\\\\n1. Creating EfficientNet model...\")\n",
    "efficientnet_model, efficientnet_base = create_transfer_learning_model('efficientnet')\n",
    "efficientnet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# MobileNet Model\n",
    "print(\"\\\\n2. Creating MobileNet model...\")\n",
    "mobilenet_model, mobilenet_base = create_transfer_learning_model('mobilenet')\n",
    "mobilenet_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\\\nAll transfer learning models created successfully!\")\n",
    "print(\"You can now train these models and compare their performance.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf24965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best transfer learning model\n",
    "print(\"Saving the best transfer learning model...\")\n",
    "resnet_model.save('plant_disease_resnet50_v2.h5')\n",
    "print(\"Model saved as 'plant_disease_resnet50_v2.h5'\")\n",
    "\n",
    "# Test prediction with transfer learning model\n",
    "print(\"\\\\nTesting prediction with transfer learning model...\")\n",
    "for images_batch, labels_batch in test_dataset.take(1):\n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "    \n",
    "    print(\"First image to predict\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(first_image)\n",
    "    plt.title(f\"Actual Disease: {class_names[first_label]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Predictions from both models\n",
    "    original_pred = model.predict(images_batch)\n",
    "    transfer_pred = resnet_model.predict(images_batch)\n",
    "    \n",
    "    print(f\"\\\\nActual Disease: {class_names[first_label]}\")\n",
    "    print(f\"Original CNN Prediction: {class_names[np.argmax(original_pred[0])]} (Confidence: {np.max(original_pred[0]):.3f})\")\n",
    "    print(f\"Transfer Learning Prediction: {class_names[np.argmax(transfer_pred[0])]} (Confidence: {np.max(transfer_pred[0]):.3f})\")\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ccff6",
   "metadata": {},
   "source": [
    "## Transfer Learning Implementation Summary\n",
    "\n",
    "**What we've implemented:**\n",
    "\n",
    "1. **Pre-trained Base Models**: ResNet50, EfficientNet, and MobileNet with ImageNet weights\n",
    "2. **Two-Phase Training**: \n",
    "   - Phase 1: Frozen base model layers (transfer learning)\n",
    "   - Phase 2: Fine-tuning with unfrozen top layers\n",
    "3. **Enhanced Data Augmentation**: Added zoom and contrast for better generalization\n",
    "4. **Advanced Callbacks**: Early stopping, learning rate reduction, and model checkpointing\n",
    "5. **Model Comparison**: Tools to compare original CNN vs transfer learning performance\n",
    "\n",
    "**Expected Benefits:**\n",
    "- **Higher Validation Accuracy**: Pre-trained features should significantly improve performance\n",
    "- **Faster Convergence**: Transfer learning typically requires fewer epochs\n",
    "- **Better Generalization**: Pre-trained models have learned robust feature representations\n",
    "- **Reduced Overfitting**: Better feature extraction reduces the need for complex architectures\n",
    "\n",
    "**Next Steps:**\n",
    "1. Run the transfer learning training cells above\n",
    "2. Compare results using the comparison function\n",
    "3. Choose the best performing model for deployment\n",
    "4. Update your API to use the new model\n",
    "\n",
    "**Tips for Best Results:**\n",
    "- Start with ResNet50 as it's proven effective for image classification\n",
    "- Monitor validation accuracy - you should see significant improvement\n",
    "- If overfitting occurs, increase dropout or reduce learning rate\n",
    "- Consider ensemble methods combining multiple pre-trained models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5933765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = '1'\n",
    "model.save(f\"../models/plant_disease_{model_version}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
